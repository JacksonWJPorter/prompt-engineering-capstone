{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from agentic.enhancer import AgenticEnhancer\n",
    "import json\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_enhancer(original_prompt):\n",
    "    \n",
    "    agentic = AgenticEnhancer(original_prompt)\n",
    "    agentic_answer = agentic.execute_workflow()\n",
    "\n",
    "    original_prompt = agentic_answer.get(\"original_prompt\")\n",
    "    original_prompt_answer = agentic_answer.get(\"original_prompt_answer\")\n",
    "    original_prompt_lin_probs = agentic_answer.get(\"original_prompt_lin_probs\")\n",
    "    enhanced_prompt = agentic_answer.get(\"enhanced_prompt\")\n",
    "    final_prompt_answer = agentic_answer.get(\"final_prompt_answer\")\n",
    "    final_prompt_lin_probs = agentic_answer.get(\"final_prompt_lin_probs\")\n",
    "    \n",
    "    final_result = {\n",
    "        \"original_prompt\": original_prompt,\n",
    "        \"original_prompt_answer\": original_prompt_answer,\n",
    "        \"original_prompt_lin_probs\": original_prompt_lin_probs,\n",
    "        \"enhanced_prompt\": enhanced_prompt,\n",
    "        \"final_prompt_answer\": final_prompt_answer,\n",
    "        \"final_prompt_lin_probs\": final_prompt_lin_probs,\n",
    "    }\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      "=== Workflow Progress ===\u001b[0m\n",
      "\u001b[32mStep 1: Categorizing Prompt\u001b[0m\n",
      "\u001b[1m\u001b[32m=====================\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[95mCategory Determined: \u001b[0m {query=\"Who is the president?\", category=\"simple question\"}\n",
      "\u001b[1m\u001b[32m\n",
      "=== Workflow Progress ===\u001b[0m\n",
      "\u001b[32mStep 1: Categorizing Prompt\u001b[0m\n",
      "\u001b[32mStep 2: Checking for Ambiguity\u001b[0m\n",
      "\u001b[1m\u001b[32m=====================\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[36mClarification Question: \u001b[0m which country are you asking about regarding the president?\n",
      "\u001b[1m\u001b[32m\n",
      "=== Workflow Progress ===\u001b[0m\n",
      "\u001b[32mStep 1: Categorizing Prompt\u001b[0m\n",
      "\u001b[32mStep 2: Checking for Ambiguity\u001b[0m\n",
      "\u001b[32mStep 3: Getting Human Feedback\u001b[0m\n",
      "\u001b[1m\u001b[32m=====================\n",
      "\u001b[0m\n",
      "\n",
      "==================================================\n",
      "\u001b[1m\u001b[33mHuman Review Required\u001b[0m\n",
      "Prompt with History:\n",
      " ###Original Prompt###: Who is the president?\n",
      "---Clarification Question: which country are you asking about regarding the president?\n",
      "---User Response: usa\n",
      "\n",
      "\n",
      "==================================================\n",
      "\u001b[1m\u001b[32m\n",
      "=== Workflow Progress ===\u001b[0m\n",
      "\u001b[32mStep 1: Categorizing Prompt\u001b[0m\n",
      "\u001b[32mStep 2: Checking for Ambiguity\u001b[0m\n",
      "\u001b[32mStep 3: Getting Human Feedback\u001b[0m\n",
      "\u001b[32mStep 4: Checking for Ambiguity\u001b[0m\n",
      "\u001b[1m\u001b[32m=====================\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[36mClarification Question: \u001b[0m clear\n",
      "\u001b[1m\u001b[32m\n",
      "=== Workflow Progress ===\u001b[0m\n",
      "\u001b[32mStep 1: Categorizing Prompt\u001b[0m\n",
      "\u001b[32mStep 2: Checking for Ambiguity\u001b[0m\n",
      "\u001b[32mStep 3: Getting Human Feedback\u001b[0m\n",
      "\u001b[32mStep 4: Checking for Ambiguity\u001b[0m\n",
      "\u001b[32mStep 5: Rephrasing Prompt\u001b[0m\n",
      "\u001b[1m\u001b[32m=====================\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[95mRephrased Prompt: \u001b[0m **Prompt:** Provide the name of the current president of the United States.\n",
      "\u001b[1m\u001b[32m\n",
      "=== Workflow Progress ===\u001b[0m\n",
      "\u001b[32mStep 1: Categorizing Prompt\u001b[0m\n",
      "\u001b[32mStep 2: Checking for Ambiguity\u001b[0m\n",
      "\u001b[32mStep 3: Getting Human Feedback\u001b[0m\n",
      "\u001b[32mStep 4: Checking for Ambiguity\u001b[0m\n",
      "\u001b[32mStep 5: Rephrasing Prompt\u001b[0m\n",
      "\u001b[32mStep 6: Enhancing Prompt\u001b[0m\n",
      "\u001b[1m\u001b[32m=====================\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[95mEnhanced Prompt: \u001b[0m **Role:** You are a knowledgeable political analyst with up-to-date information on current world leaders.\n",
      "\n",
      "**Prompt:** Please provide the name of the current President of the United States as of October 2023.\n",
      "\u001b[1m\u001b[32m\n",
      "=== Workflow Progress ===\u001b[0m\n",
      "\u001b[32mStep 1: Categorizing Prompt\u001b[0m\n",
      "\u001b[32mStep 2: Checking for Ambiguity\u001b[0m\n",
      "\u001b[32mStep 3: Getting Human Feedback\u001b[0m\n",
      "\u001b[32mStep 4: Checking for Ambiguity\u001b[0m\n",
      "\u001b[32mStep 5: Rephrasing Prompt\u001b[0m\n",
      "\u001b[32mStep 6: Enhancing Prompt\u001b[0m\n",
      "\u001b[32mStep 7: Generating Final Answer\u001b[0m\n",
      "\u001b[1m\u001b[32m=====================\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[34mFinal Prompt: \u001b[0m **Role:** You are a knowledgeable political analyst with up-to-date information on current world leaders.\n",
      "\n",
      "**Prompt:** Please provide the name of the current President of the United States as of October 2023.\n",
      "\u001b[1m\u001b[34mFinal Answer: \u001b[0m As of October 2023, the current President of the United States is Joe Biden. He has been in office since January 20, 2021.\n",
      "\u001b[1m\u001b[34mFinal Lin Probs: \u001b[0m 0.9735473465337515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>original_prompt_answer</th>\n",
       "      <th>original_prompt_lin_probs</th>\n",
       "      <th>enhanced_prompt</th>\n",
       "      <th>final_prompt_answer</th>\n",
       "      <th>final_prompt_lin_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the president?</td>\n",
       "      <td>No original answer provided</td>\n",
       "      <td>N/A</td>\n",
       "      <td>**Role:** You are a knowledgeable political an...</td>\n",
       "      <td>As of October 2023, the current President of t...</td>\n",
       "      <td>0.973547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         original_prompt       original_prompt_answer  \\\n",
       "0  Who is the president?  No original answer provided   \n",
       "\n",
       "  original_prompt_lin_probs  \\\n",
       "0                       N/A   \n",
       "\n",
       "                                     enhanced_prompt  \\\n",
       "0  **Role:** You are a knowledgeable political an...   \n",
       "\n",
       "                                 final_prompt_answer  final_prompt_lin_probs  \n",
       "0  As of October 2023, the current President of t...                0.973547  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with open('data/prompts.json', 'r') as f:\n",
    "#     original_prompt = json.load(f)\n",
    "\n",
    "# df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"original_prompt\": original_prompt,\n",
    "#         \"original_prompt_answer\": [None]*len(original_prompt),\n",
    "#         \"original_prompt_lin_probs\": [None]*len(original_prompt),\n",
    "#         \"enhanced_prompt\": [None]*len(original_prompt),\n",
    "#         \"final_prompt_answer\": [None]*len(original_prompt),\n",
    "#         \"final_prompt_lin_probs\": [None]*len(original_prompt),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# display(df.head(5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test with a single prompt\n",
    "test_prompt = \"Who is the president?\"\n",
    "final_result = agentic_enhancer(test_prompt)\n",
    "\n",
    "# Create DataFrame with single result, now including evaluation metrics\n",
    "df = pd.DataFrame([{\n",
    "    \"original_prompt\": test_prompt,\n",
    "    \"original_prompt_answer\": final_result['original_prompt_answer'],\n",
    "    \"original_prompt_lin_probs\": final_result['original_prompt_lin_probs'],\n",
    "    \"enhanced_prompt\": final_result['enhanced_prompt'],\n",
    "    \"final_prompt_answer\": final_result['final_prompt_answer'],\n",
    "    \"final_prompt_lin_probs\": final_result['final_prompt_lin_probs'],\n",
    "    # New evaluation columns\n",
    "    \"evaluation_score\": final_result.get('prompt_evaluation', {}).get('overall_score', None),\n",
    "    \"clarity_score\": final_result.get('prompt_evaluation', {}).get('scores', {}).get('clarity', None),\n",
    "    \"specificity_score\": final_result.get('prompt_evaluation', {}).get('scores', {}).get('specificity', None),\n",
    "    \"completeness_score\": final_result.get('prompt_evaluation', {}).get('scores', {}).get('completeness', None),\n",
    "    \"structure_score\": final_result.get('prompt_evaluation', {}).get('scores', {}).get('structure', None),\n",
    "    \"task_focus_score\": final_result.get('prompt_evaluation', {}).get('scores', {}).get('task_focus', None),\n",
    "    \"improvement_needed\": final_result.get('prompt_evaluation', {}).get('needs_improvement', None)\n",
    "}])\n",
    "\n",
    "# Display the results with evaluation metrics\n",
    "display(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95mCategory Determined: \u001b[0m summary\n",
      "\u001b[1m\u001b[36mClarification Question: \u001b[0m clear\n",
      "\u001b[1m\u001b[95mRephrased Prompt: \u001b[0m **Desired Output:** Provide a list of the most common methods for reducing carbon emissions.\n",
      "\n",
      "**Context:** The user is seeking information on effective strategies or practices that can be implemented to lower carbon emissions, potentially for personal, organizational, or governmental use.\n",
      "\n",
      "**Rephrased Prompt:**  \n",
      "\"What are the most common and effective methods for reducing carbon emissions, including strategies applicable to individuals, organizations, and governments?\"\n",
      "\u001b[1m\u001b[95mEnhanced Prompt: \u001b[0m **Role:** Environmental Policy Advisor\n",
      "\n",
      "---\n",
      "\n",
      "**Task:** Provide a comprehensive overview of carbon emission reduction strategies.\n",
      "\n",
      "---\n",
      "\n",
      "**Desired Output:**  \n",
      "Please provide a detailed list of the **most common and effective methods** for reducing carbon emissions. \n",
      "\n",
      "**Context:** The user is seeking information on effective strategies or practices that can be implemented to lower carbon emissions, applicable to **individuals**, **organizations**, and **governments**. \n",
      "\n",
      "**Rephrased Prompt:**  \n",
      "\"What are the most common and effective methods for reducing carbon emissions? Please include strategies that can be implemented by individuals, organizations, and governments, along with any relevant examples or best practices.\"\n",
      "\u001b[1m\u001b[34mFinal Prompt: \u001b[0m **Role:** Environmental Policy Advisor\n",
      "\n",
      "---\n",
      "\n",
      "**Task:** Provide a comprehensive overview of carbon emission reduction strategies.\n",
      "\n",
      "---\n",
      "\n",
      "**Desired Output:**  \n",
      "Please provide a detailed list of the **most common and effective methods** for reducing carbon emissions. \n",
      "\n",
      "**Context:** The user is seeking information on effective strategies or practices that can be implemented to lower carbon emissions, applicable to **individuals**, **organizations**, and **governments**. \n",
      "\n",
      "**Rephrased Prompt:**  \n",
      "\"What are the most common and effective methods for reducing carbon emissions? Please include strategies that can be implemented by individuals, organizations, and governments, along with any relevant examples or best practices.\"\n",
      "\u001b[1m\u001b[34mFinal Answer: \u001b[0m Reducing carbon emissions is critical for combating climate change and promoting sustainability. Here’s a comprehensive overview of the most common and effective strategies that can be implemented by individuals, organizations, and governments:\n",
      "\n",
      "### 1. **Energy Efficiency Improvements**\n",
      "   - **Individuals:** Upgrade to energy-efficient appliances (e.g., ENERGY STAR-rated products), use LED lighting, and improve home insulation.\n",
      "   - **Organizations:** Conduct energy audits, implement energy management systems, and invest in energy-efficient technologies (e.g., HVAC systems).\n",
      "   - **Governments:** Set energy efficiency standards and provide incentives for energy-efficient upgrades in residential and commercial buildings.\n",
      "\n",
      "### 2. **Renewable Energy Adoption**\n",
      "   - **Individuals:** Install solar panels or participate in community solar programs.\n",
      "   - **Organizations:** Transition to renewable energy sources (solar, wind, geothermal) for operations and invest in renewable energy certificates (RECs).\n",
      "   - **Governments:** Implement policies to promote renewable energy development, such as tax credits, subsidies, and renewable portfolio standards.\n",
      "\n",
      "### 3. **Sustainable Transportation**\n",
      "   - **Individuals:** Use public transportation, carpool, bike, or walk when possible; consider electric or hybrid vehicles.\n",
      "   - **Organizations:** Encourage telecommuting, provide incentives for public transport use, and invest in electric vehicle (EV) charging infrastructure.\n",
      "   - **Governments:** Develop public transit systems, create bike lanes, and implement policies to reduce vehicle emissions (e.g., emissions standards).\n",
      "\n",
      "### 4. **Waste Reduction and Management**\n",
      "   - **Individuals:** Practice recycling, composting, and reducing single-use plastics.\n",
      "   - **Organizations:** Implement waste reduction programs, conduct waste audits, and promote circular economy practices.\n",
      "   - **Governments:** Enforce regulations on waste management, support recycling initiatives, and promote zero-waste policies.\n",
      "\n",
      "### 5. **Carbon Offsetting**\n",
      "   - **Individuals:** Purchase carbon offsets to compensate for personal emissions (e.g., through tree planting or renewable energy projects).\n",
      "   - **Organizations:** Invest in carbon offset programs to balance out emissions from operations and supply chains.\n",
      "   - **Governments:** Support and regulate carbon offset markets to ensure transparency and effectiveness.\n",
      "\n",
      "### 6. **Sustainable Agriculture and Land Use**\n",
      "   - **Individuals:** Support local and organic farming, reduce meat consumption, and grow food in home gardens.\n",
      "   - **Organizations:** Implement sustainable sourcing policies, reduce food waste, and adopt regenerative agricultural practices.\n",
      "   - **Governments:** Promote sustainable land use policies, support agroforestry, and incentivize practices that enhance carbon sequestration in soils.\n",
      "\n",
      "### 7. **Carbon Capture and Storage (CCS)**\n",
      "   - **Individuals:** While direct implementation is limited, individuals can support policies and technologies that promote CCS.\n",
      "   - **Organizations:** Invest in CCS technologies to capture emissions from industrial processes.\n",
      "   - **Governments:** Fund research and development of CCS technologies and create regulatory frameworks to support their deployment.\n",
      "\n",
      "### 8. **Behavioral Change and Education**\n",
      "   - **Individuals:** Educate oneself and others about carbon footprints and sustainable practices; participate in community initiatives.\n",
      "   - **Organizations:** Conduct training and awareness programs for employees on sustainability practices.\n",
      "   - **Governments:** Launch public awareness campaigns to promote sustainable behaviors and educate citizens on climate change impacts.\n",
      "\n",
      "### 9. **Policy and Regulation**\n",
      "   - **Individuals:** Advocate for local and national policies that support carbon reduction.\n",
      "   - **Organizations:** Engage in policy advocacy and collaborate with stakeholders to promote sustainable practices.\n",
      "   - **Governments:** Implement carbon pricing (cap-and-trade systems or carbon taxes), set emissions reduction targets, and enforce environmental regulations.\n",
      "\n",
      "### 10. **Research and Innovation**\n",
      "   - **Individuals:** Support and engage in community science projects focused on sustainability.\n",
      "   - **Organizations:** Invest in research and development of low-carbon technologies and sustainable practices.\n",
      "   - **Governments:** Fund research initiatives and partnerships with universities and private sectors to drive innovation in carbon reduction technologies.\n",
      "\n",
      "### Conclusion\n",
      "Implementing these strategies requires a collaborative effort across all sectors of society. By adopting a combination of these methods, individuals, organizations, and governments can significantly reduce carbon emissions and contribute to a more sustainable future. Each strategy can be tailored to specific contexts and needs, ensuring that efforts are both effective and impactful.\n",
      "\u001b[1m\u001b[34mFinal Lin Probs: \u001b[0m 0.7720800114821035\n",
      "\u001b[1m\u001b[95mCategory Determined: \u001b[0m creative-writing-and-ideation\n",
      "\u001b[1m\u001b[36mClarification Question: \u001b[0m what type of name are you looking for—something fun, serious, or themed?\n",
      "\n",
      "==================================================\n",
      "\u001b[1m\u001b[33mHuman Review Required\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      2\u001b[0m     original_prompt \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     final_result \u001b[38;5;241m=\u001b[39m \u001b[43magentic_enhancer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_prompt_answer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_prompt_answer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_prompt_lin_probs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_prompt_lin_probs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36magentic_enhancer\u001b[0;34m(original_prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magentic_enhancer\u001b[39m(original_prompt):\n\u001b[1;32m      3\u001b[0m     agentic \u001b[38;5;241m=\u001b[39m AgenticEnhancer(original_prompt)\n\u001b[0;32m----> 4\u001b[0m     agentic_answer \u001b[38;5;241m=\u001b[39m \u001b[43magentic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     original_prompt \u001b[38;5;241m=\u001b[39m agentic_answer\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     original_prompt_answer \u001b[38;5;241m=\u001b[39m agentic_answer\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_prompt_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/projects/prompt-engineering-capstone/agentic/enhancer.py:146\u001b[0m, in \u001b[0;36mAgenticEnhancer.execute_workflow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_workflow\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m         final_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                                      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjackson-test-chat-id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         final_state_formatted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_final_state(final_state)\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m final_state_formatted\n",
      "File \u001b[0;32m~/Desktop/projects/venv/lib/python3.9/site-packages/langgraph/pregel/__init__.py:1918\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1917\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1920\u001b[0m     config,\n\u001b[1;32m   1921\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1922\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1923\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1924\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1925\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1927\u001b[0m ):\n\u001b[1;32m   1928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1929\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/Desktop/projects/venv/lib/python3.9/site-packages/langgraph/pregel/__init__.py:1646\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1646\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1647\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1648\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1649\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1650\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1651\u001b[0m         ):\n\u001b[1;32m   1652\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/projects/venv/lib/python3.9/site-packages/langgraph/pregel/runner.py:104\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    102\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/projects/venv/lib/python3.9/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, writer)\u001b[0m\n\u001b[1;32m     38\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/projects/venv/lib/python3.9/site-packages/langgraph/utils/runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Desktop/projects/venv/lib/python3.9/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Desktop/projects/prompt-engineering-capstone/agentic/nodes.py:52\u001b[0m, in \u001b[0;36mBaseNode.__call__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: GraphState) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GraphState:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/prompt-engineering-capstone/agentic/nodes.py:387\u001b[0m, in \u001b[0;36mHumanNode.process\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    385\u001b[0m lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m line:\n\u001b[1;32m    389\u001b[0m         lines\u001b[38;5;241m.\u001b[39mappend(line)\n",
      "File \u001b[0;32m~/Desktop/projects/venv/lib/python3.9/site-packages/ipykernel/kernelbase.py:1187\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/venv/lib/python3.9/site-packages/ipykernel/kernelbase.py:1230\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    original_prompt = row['original_prompt']\n",
    "    final_result = agentic_enhancer(original_prompt)\n",
    "    \n",
    "    df.at[i, 'original_prompt_answer'] = final_result['original_prompt_answer']\n",
    "    df.at[i, 'original_prompt_lin_probs'] = final_result['original_prompt_lin_probs']\n",
    "    df.at[i, 'enhanced_prompt'] = final_result['enhanced_prompt']\n",
    "    df.at[i, 'final_prompt_answer'] = final_result['final_prompt_answer']\n",
    "    df.at[i, 'final_prompt_lin_probs'] = final_result['final_prompt_lin_probs']\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/enhancement_results_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_prompt_answer</th>\n",
       "      <th>original_prompt_lin_probs</th>\n",
       "      <th>enhanced_prompt</th>\n",
       "      <th>final_prompt_answer</th>\n",
       "      <th>final_prompt_lin_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_prompt_answer  original_prompt_lin_probs  enhanced_prompt  \\\n",
       "0                     NaN                        NaN              NaN   \n",
       "1                     NaN                        NaN              NaN   \n",
       "2                     NaN                        NaN              NaN   \n",
       "3                     NaN                        NaN              NaN   \n",
       "4                     NaN                        NaN              NaN   \n",
       "\n",
       "   final_prompt_answer  final_prompt_lin_probs  \n",
       "0                  NaN                     NaN  \n",
       "1                  NaN                     NaN  \n",
       "2                  NaN                     NaN  \n",
       "3                  NaN                     NaN  \n",
       "4                  NaN                     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('results/enhancement_results_1.csv').iloc[:, 1:]\n",
    "df['original_prompt_lin_probs'] = df['original_prompt_lin_probs'].apply(lambda x: round(x, 6))\n",
    "\n",
    "mask = df['original_prompt_lin_probs'] < 0.20\n",
    "df.loc[mask, 'original_prompt_lin_probs'] = 0.50\n",
    "\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       original_prompt_answer  original_prompt_lin_probs  enhanced_prompt  \\\n",
      "count                     0.0                        0.0              0.0   \n",
      "mean                      NaN                        NaN              NaN   \n",
      "std                       NaN                        NaN              NaN   \n",
      "min                       NaN                        NaN              NaN   \n",
      "25%                       NaN                        NaN              NaN   \n",
      "50%                       NaN                        NaN              NaN   \n",
      "75%                       NaN                        NaN              NaN   \n",
      "max                       NaN                        NaN              NaN   \n",
      "\n",
      "       final_prompt_answer  final_prompt_lin_probs  \n",
      "count                  0.0                     0.0  \n",
      "mean                   NaN                     NaN  \n",
      "std                    NaN                     NaN  \n",
      "min                    NaN                     NaN  \n",
      "25%                    NaN                     NaN  \n",
      "50%                    NaN                     NaN  \n",
      "75%                    NaN                     NaN  \n",
      "max                    NaN                     NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate and visualize average improvement percentage\n",
    "def plot_improvement_distribution():\n",
    "    # Calculate improvement percentage\n",
    "    df['improvement_percentage'] = ((df['final_prompt_lin_probs'] - df['original_prompt_lin_probs']) \n",
    "                                  / df['original_prompt_lin_probs'] * 100)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(data=df, x='improvement_percentage', fill=True, color='skyblue')\n",
    "    plt.axvline(df['improvement_percentage'].mean(), color='r', linestyle='--', \n",
    "                label=f'Mean Improvement: {df[\"improvement_percentage\"].mean():.1f}%')\n",
    "    \n",
    "    plt.title('Distribution of Prompt Enhancement Improvements')\n",
    "    plt.xlabel('Improvement Percentage')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average improvement: {df['improvement_percentage'].mean():.1f}%\")\n",
    "    print(f\"Maximum improvement: {df['improvement_percentage'].max():.1f}%\")\n",
    "    print(f\"Minimum improvement: {df['improvement_percentage'].min():.1f}%\")\n",
    "\n",
    "# 2. Compare original vs enhanced confidence scores\n",
    "def plot_confidence_comparison():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    indices = range(len(df))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(indices, df['original_prompt_lin_probs'], width, \n",
    "            label='Original Confidence', color='lightblue')\n",
    "    plt.bar([i + width for i in indices], df['final_prompt_lin_probs'], width,\n",
    "            label='Enhanced Confidence', color='darkblue')\n",
    "    \n",
    "    plt.xlabel('Prompt Index')\n",
    "    plt.ylabel('Model Confidence (Linear Probability)')\n",
    "    plt.title('Original vs Enhanced Prompt Confidence')\n",
    "    plt.legend()\n",
    "    plt.xticks([i + width/2 for i in indices], indices)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_improvement_distribution()\n",
    "plot_confidence_comparison()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
