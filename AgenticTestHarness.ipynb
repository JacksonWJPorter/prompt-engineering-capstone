{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from agentic.enhancer import AgenticEnhancer\n",
    "import json\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_enhancer(original_prompt):\n",
    "    \n",
    "    agentic = AgenticEnhancer(original_prompt)\n",
    "    agentic_answer = agentic.execute_workflow()\n",
    "\n",
    "    original_prompt = agentic_answer.get(\"original_prompt\")\n",
    "    original_prompt_answer = agentic_answer.get(\"original_prompt_answer\")\n",
    "    original_prompt_lin_probs = agentic_answer.get(\"original_prompt_lin_probs\")\n",
    "    enhanced_prompt = agentic_answer.get(\"enhanced_prompt\")\n",
    "    final_prompt_answer = agentic_answer.get(\"final_prompt_answer\")\n",
    "    final_prompt_lin_probs = agentic_answer.get(\"final_prompt_lin_probs\")\n",
    "    \n",
    "    # More thoroughly remove markdown formatting\n",
    "    if enhanced_prompt and isinstance(enhanced_prompt, str):\n",
    "        # Remove common markdown formatting\n",
    "        enhanced_prompt = enhanced_prompt.replace('**', '')\n",
    "        enhanced_prompt = enhanced_prompt.replace('*', '')\n",
    "        \n",
    "        # Remove headings (# to ######)\n",
    "        for i in range(1, 7):\n",
    "            heading_marker = '#' * i + ' '\n",
    "            enhanced_prompt = enhanced_prompt.replace(heading_marker, '')\n",
    "        enhanced_prompt = enhanced_prompt.replace('#', '')\n",
    "        \n",
    "        # Remove other common markdown elements\n",
    "        enhanced_prompt = enhanced_prompt.replace('===', '')\n",
    "        enhanced_prompt = enhanced_prompt.replace('---', '')\n",
    "        enhanced_prompt = enhanced_prompt.replace('```', '')\n",
    "        enhanced_prompt = enhanced_prompt.replace('`', '')\n",
    "        enhanced_prompt = enhanced_prompt.replace('> ', '')\n",
    "        \n",
    "        # Replace markdown list markers with plain text alternatives\n",
    "        lines = enhanced_prompt.split('\\n')\n",
    "        for i in range(len(lines)):\n",
    "            # Replace bullet points and numbered lists\n",
    "            lines[i] = lines[i].replace('- ', 'â€¢ ')\n",
    "            lines[i] = lines[i].lstrip('1234567890. ')\n",
    "        \n",
    "        # Put it back together\n",
    "        enhanced_prompt = '\\n'.join(lines)\n",
    "        \n",
    "        # Clean up any double spaces resulting from replacements\n",
    "        while '  ' in enhanced_prompt:\n",
    "            enhanced_prompt = enhanced_prompt.replace('  ', ' ')\n",
    "        \n",
    "        # Clean up any extra newlines\n",
    "        while '\\n\\n\\n' in enhanced_prompt:\n",
    "            enhanced_prompt = enhanced_prompt.replace('\\n\\n\\n', '\\n\\n')\n",
    "        \n",
    "    final_result = {\n",
    "        \"original_prompt\": original_prompt,\n",
    "        \"original_prompt_answer\": original_prompt_answer,\n",
    "        \"original_prompt_lin_probs\": original_prompt_lin_probs,\n",
    "        \"enhanced_prompt\": enhanced_prompt,\n",
    "        \"final_prompt_answer\": final_prompt_answer,\n",
    "        \"final_prompt_lin_probs\": final_prompt_lin_probs,\n",
    "    }\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95mCategory Determined: \u001b[0m {query=\"who is the president\", category=\"simple question\"}\n",
      "\u001b[1m\u001b[95mRephrased Prompt: \u001b[0m **Prompt:**  \n",
      "\"Please provide the name of the current president of the United States as of October 2023.\"\n",
      "\u001b[1m\u001b[95mEnhanced Prompt: \u001b[0m Role: You are a knowledgeable political analyst tasked with providing accurate and up-to-date information.\n",
      "\n",
      "User Prompt: \n",
      "Please provide the name of the CURRENT PRESIDENT OF THE UNITED STATES as of OCTOBER 2023.\n",
      "\n",
      "=== PROMPT EVALUATION ===\n",
      "Score: \u001b[31m32\u001b[0m\n",
      "Score Justification: The prompt is a basic factual question but lacks specificity regarding which president is being referred to, leading to a lower score.\n",
      "\n",
      "Improvement Suggestions:\n",
      "1. Specify which country's president is being asked about to enhance clarity.\n",
      "2. Provide context or timeframe to narrow down the inquiry (e.g., current president, historical context).\n",
      "3. Indicate the desired format for the response (e.g., name only, brief biography).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>original_prompt_answer</th>\n",
       "      <th>original_prompt_lin_probs</th>\n",
       "      <th>enhanced_prompt</th>\n",
       "      <th>final_prompt_answer</th>\n",
       "      <th>final_prompt_lin_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who is the president</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>Role: You are a knowledgeable political analyst tasked with providing accurate and up-to-date information.\\n\\nUser Prompt: \\nPlease provide the name of the CURRENT PRESIDENT OF THE UNITED STATES as of OCTOBER 2023.</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        original_prompt original_prompt_answer  original_prompt_lin_probs  \\\n",
       "0  who is the president                                               0.0   \n",
       "\n",
       "                                                                                                                                                                                                          enhanced_prompt  \\\n",
       "0  Role: You are a knowledgeable political analyst tasked with providing accurate and up-to-date information.\\n\\nUser Prompt: \\nPlease provide the name of the CURRENT PRESIDENT OF THE UNITED STATES as of OCTOBER 2023.   \n",
       "\n",
       "  final_prompt_answer  final_prompt_lin_probs  \n",
       "0                                         0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with open('data/prompts.json', 'r') as f:\n",
    "#     original_prompt = json.load(f)\n",
    "\n",
    "# df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"original_prompt\": original_prompt,\n",
    "#         \"original_prompt_answer\": [None]*len(original_prompt),\n",
    "#         \"original_prompt_lin_probs\": [None]*len(original_prompt),\n",
    "#         \"enhanced_prompt\": [None]*len(original_prompt),\n",
    "#         \"final_prompt_answer\": [None]*len(original_prompt),\n",
    "#         \"final_prompt_lin_probs\": [None]*len(original_prompt),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# display(df.head(5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test with a single prompt\n",
    "test_prompt = \"who is the president\"\n",
    "enhancer = AgenticEnhancer(test_prompt)\n",
    "final_result = enhancer.execute_workflow()\n",
    "\n",
    "# Create DataFrame with single result\n",
    "df = pd.DataFrame([{\n",
    "    \"original_prompt\": test_prompt,\n",
    "    \"original_prompt_answer\": final_result.get('original_prompt_answer', ''),\n",
    "    \"original_prompt_lin_probs\": final_result.get('original_prompt_lin_probs', 0.0),\n",
    "    \"enhanced_prompt\": final_result.get('enhanced_prompt', ''),\n",
    "    \"final_prompt_answer\": final_result.get('final_prompt_answer', ''),\n",
    "    \"final_prompt_lin_probs\": final_result.get('final_prompt_lin_probs', 0.0),\n",
    "}])\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    original_prompt = row['original_prompt']\n",
    "    final_result = agentic_enhancer(original_prompt)\n",
    "    \n",
    "    df.at[i, 'original_prompt_answer'] = final_result['original_prompt_answer']\n",
    "    df.at[i, 'original_prompt_lin_probs'] = final_result['original_prompt_lin_probs']\n",
    "    df.at[i, 'enhanced_prompt'] = final_result['enhanced_prompt']\n",
    "    df.at[i, 'final_prompt_answer'] = final_result['final_prompt_answer']\n",
    "    df.at[i, 'final_prompt_lin_probs'] = final_result['final_prompt_lin_probs']\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/enhancement_results_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/enhancement_results_1.csv').iloc[:, 1:]\n",
    "df['original_prompt_lin_probs'] = df['original_prompt_lin_probs'].apply(lambda x: round(x, 6))\n",
    "\n",
    "mask = df['original_prompt_lin_probs'] < 0.20\n",
    "df.loc[mask, 'original_prompt_lin_probs'] = 0.50\n",
    "\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate and visualize average improvement percentage\n",
    "def plot_improvement_distribution():\n",
    "    # Calculate improvement percentage\n",
    "    df['improvement_percentage'] = ((df['final_prompt_lin_probs'] - df['original_prompt_lin_probs']) \n",
    "                                  / df['original_prompt_lin_probs'] * 100)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(data=df, x='improvement_percentage', fill=True, color='skyblue')\n",
    "    plt.axvline(df['improvement_percentage'].mean(), color='r', linestyle='--', \n",
    "                label=f'Mean Improvement: {df[\"improvement_percentage\"].mean():.1f}%')\n",
    "    \n",
    "    plt.title('Distribution of Prompt Enhancement Improvements')\n",
    "    plt.xlabel('Improvement Percentage')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average improvement: {df['improvement_percentage'].mean():.1f}%\")\n",
    "    print(f\"Maximum improvement: {df['improvement_percentage'].max():.1f}%\")\n",
    "    print(f\"Minimum improvement: {df['improvement_percentage'].min():.1f}%\")\n",
    "\n",
    "# 2. Compare original vs enhanced confidence scores\n",
    "def plot_confidence_comparison():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    indices = range(len(df))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(indices, df['original_prompt_lin_probs'], width, \n",
    "            label='Original Confidence', color='lightblue')\n",
    "    plt.bar([i + width for i in indices], df['final_prompt_lin_probs'], width,\n",
    "            label='Enhanced Confidence', color='darkblue')\n",
    "    \n",
    "    plt.xlabel('Prompt Index')\n",
    "    plt.ylabel('Model Confidence (Linear Probability)')\n",
    "    plt.title('Original vs Enhanced Prompt Confidence')\n",
    "    plt.legend()\n",
    "    plt.xticks([i + width/2 for i in indices], indices)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_improvement_distribution()\n",
    "plot_confidence_comparison()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
